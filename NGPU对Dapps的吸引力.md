## NGPU的优势

### 针对个人开发者的优势
个人开发者在寻找使用GPU算力时的关注点在于：

+ **成本敏感**：作为个人开发者最为关注的是投入成本，因此对于GPU算力的价格非常敏感。
+ **便于开发**：作为个人开发者希望能在短时间内快速验证自己的产品想法，因此对能快速实现自己产品功能的平台很受欢迎。


对于个人开发者来说，使用NGPU平台来为他的应用提供GPU算力服务是合适的，原因：

**<span style="color:green;">成本敏感</span>**
1. NGPU采用的去中心化算力，让闲置算力为个人开发者提供GPU算力服务，因此购置价格会很低。

**<span style="color:green;">便于开发</span>**
1. 对于没有集群化开发能力的个人开发者来说， NGPU平台封装了完整的GPU算力监控、GPU算力智能调度功能，省去了个人开发者自己开发算力监控、算力调度、算力队列等开发工作量。
2. NGPU提供大量的接口API，满足个人开发者用户对于任务调度、任务进度查询、每天、每小时任务汇总、AI任务的算力消耗概要、详细查询等等。减少了个人开发者在这方面的开发时间投入。
3. NGPU提供了DashBoard相关页面插件，让个人开发者可以非常直观检测到自己每条AI任务详细信息与GPU消耗情况。

+ 案例1：
```json
    比如个人开发者小红, 当小红把自己的业务部署在aws的一台服务器(假设$3000/月), 然后去推广了一个月, 假设使用量1, 那么小红在这一个月中为了它程序的正常运行白白花费了3000块, 造成了资源浪费、分配不均的一些问题, 如果把这3000块花在推广上可能会更利好产品。如果使用NGPU, 小红无需付出3000块来维护他的程序运行, 平台会保证程序的长期在线, 当小红业务存在使用量时才会扣除相应的使用费. 比如小红程序在单次被调用时gas fee 是 10块, 当小红去推广一个月是, 使用量为1, 则小红一个月的花费仅仅是10块钱. 
```
+ 案例2：
```
    开发者小明（化名）在AI大潮来临时，尝试提供图片按照特定风格转化的服务。而这个基于Stable diffusion的AI服务需要15G显存，AWS上采用配备T4 16GB g4ad.xlarge，不包含网络服务的基础价格为每小时0.379 USD，对应每月价格272.88 USD。而NGPU 3090 24GB 按照实际使用市场每秒价格为0.000366 USD。以每张图耗时10秒计算，则每张图的成本为0.00366 USD。相比于AWS的月报价，每月当生成图片数量小于 74557（ 272.88/ 0.00366）张时，采用NGPU划算。反之则是AWS划算。

    对于小的开发者来说，受限于推广能力，每月作图订单数量远小于74557张，仅在3000张上下，这样采用NGPU实际使用量计费仅需要10.98 USD，是AWS的4%。另外，小明在NGPU平台仅需要部署AI作图镜像，既可以调用平台的集群服务能力，避免单个服务器故障带来的停服风险，简化了开发与运维。而NGPU的弹性扩缩容，有力的确保了瞬时作图订单拥挤时候也能顺畅服务，不至于负载过高而停止服务。

```


### 针对小B端团队的优势
对于小B端团队在寻找使用GPU算力时的关注点在于：

+ **便于开发**：小B端团队成本有限，因此希望对接的GPU算力平台能够提供尽量多的功能（任务汇总、任务信息、调度信息等等），这样可以节省小B端开发成本，加快产品上线时间。
+ **能处理任务的波峰波谷**：小B团队的产品一般产品较小，因此在预估终端用户或者AI任务请求数量时经常出现偏差。从而造成租用算力服务器过剩或者不足从而产生AI任务的波峰与波谷。过剩时浪费了租用成本，不足时无法及时响应大量用户的请求。
+ **业务稳定运行**：小B端团队获得用户不易，当业务无法稳定运行时，会失去用户，因此小B端团队希望使用的GPU算力能够稳定的为业务提供算力服务。

对于小B端开发团队来说，使用NGPU平台为他们的应用提供算力非常合适，原因：

**<span style="color:green;">便于开发</span>**
1. 与针对个人开发者相同，NGPU提供了大量的API接口以及SDK包，从而节省了小B端团队的开发工作量。
2. NGPU的智能调度的引入省去了小B端需要自己开发GPU算力调度的开发工作量。


**<span style="color:green;">能处理任务的波峰波谷</span>**
1. NGPU是一个弹性算力网络，当工作空间对GPU算力的需求量超过阈值时，会自动进行弹性扩容。而且弹性扩容后的GPU算力节点能够正常的为用户的AI任务提供服务。避免出现AI任务积压，影响业务。
2. NGPU采用按照每次AI任务实际消耗GPU量来进行汇总与计费，pay-as-usage（按使用量付费）最大程度上节省资源使用费。

**<span style="color:green;">业务稳定运行</span>**
1. NGPU实时监控AI应用的负载情况， 采用智能调度方式，当GPU算力掉线时会自动调用到另一个能够提供AI任务的算力节点，因此即便是GPU算力节点掉线，也不会影响到业务的稳定性运行。


+ 案例3：
```json
    案例1中的小红不幸去世, 但是他的程序受很多人喜欢, 如果它选用的是aws, 可能人们就无法再使用小红的程序功能了。如果使用NGPU 就算小红去世了, 使用这个程序功能的人还是可以继续使用当前的功能. 这种理念与solidity可信赖和持久的理念不谋而合
```


